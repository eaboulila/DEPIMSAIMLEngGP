# ğŸš— Real-Time Object Detection for Autonomous Vehicles

> A real-time, edge-optimized deep learning perception module for autonomous driving systems.
> Developed under the Digital Egypt Pioneers Initiative (DEPI) â€“ AI & Machine Learning Track (2025).

## ğŸ“Œ Project Overview

Autonomous vehicles require **low-latency, high-accuracy environmental perception** to ensure safe navigation.

This project presents a **YOLOv8-based real-time object detection system** optimized for edge deployment using **ONNX and TensorRT**, achieving:

* âš¡ **78.5 ms inference latency**
* ğŸ¯ **71.1% mAP@50**
* ğŸš˜ Multi-class detection for driving-critical objects
* ğŸ§  Full MLOps monitoring pipeline

## ğŸ§  Architecture
<img width="2471" height="164" alt="mermaid-diagram" src="https://github.com/user-attachments/assets/72ab2aa1-d928-48d3-a072-df76d71d0076" />

## ğŸ¯ Problem Statement

Autonomous systems often struggle with:

* Low-light and night driving
* Fog, rain, and weather interference
* Small object detection (traffic lights, distant pedestrians)
* Real-time latency constraints

We built a perception module that balances:

* âœ… Accuracy
* âœ… Speed
* âœ… Edge deployability
* âœ… Safety-critical robustness

## ğŸ§  Model Architecture

We selected **YOLOv8** due to:

* Anchor-free detection head
* C2f backbone blocks
* Efficient gradient flow
* Native ONNX & TensorRT export
* Strong small-object detection performance

### Detection Pipeline

```
Live Camera Feed
        â†“
Frame Preprocessing (Resize 640x640)
        â†“
YOLOv8 Inference
        â†“
NMS & Post-processing
        â†“
Structured Detection Output
```

## ğŸ“Š Dataset Strategy

### ğŸ“¦ Datasets Used

* KITTI (Autonomous Driving Focused)
* COCO (Transfer Learning Base)
* OpenImages (Edge Cases & Diversity)

### ğŸ”„ Data Engineering

* Multi-dataset fusion
* Class balancing
* YOLO format conversion
* Scene-leakage prevention
* Annotation normalization

### ğŸŒ§ï¸ Custom Augmentation Pipeline

* Night simulation
* Fog & rain injection
* Motion blur
* Mosaic augmentation
* Brightness/contrast shifts

## ğŸ‹ï¸ Training Configuration

| Parameter       | Value   |
| --------------- | ------- |
| Model           | YOLOv8  |
| Image Size      | 512     |
| Batch Size      | 16      |
| Optimizer       | AdamW   |
| LR              | 0.0032  |
| Epochs          | 80      |
| Mixed Precision | Enabled |

### ğŸ”¬ Experiments Conducted

* Baseline
* Augmentation testing
* Hyperparameter tuning (Optuna)
* Image size benchmarking
* Fine-tuning strategy

Tracked with **MLflow**.

## ğŸ“ˆ Performance Results

| Metric               | Result                             |
| -------------------- | ---------------------------------- |
| Inference Latency    | **78.5 ms**                        |
| mAP@50               | **71.1%**                          |
| FPS (Edge Optimized) | 35â€“45 FPS                          |
| Target Latency       | < 200 ms (Exceeded by 2.5Ã— faster) |

### Key Observations

* +12.7% accuracy gain after extended tuning
* Strong generalization in urban scenarios
* Remaining challenge: small traffic light detection

## âš™ï¸ Deployment & Optimization

### Model Export

* PyTorch (.pt)
* ONNX (.onnx)
* TensorRT Engine (.engine)

### Edge Optimization

* FP16 quantization
* Threaded inference pipeline
* Hardware-aware tuning
* Jetson validation

## ğŸ”„ MLOps Integration

Built full monitoring pipeline:

* Model versioning (MLflow)
* Dataset versioning (DVC)
* Drift detection
* FPS & latency monitoring
* Automated retraining triggers
* Confidence distribution tracking

## ğŸ— Project Structure

```
â”œâ”€â”€ data/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ deployment/
â”‚   â””â”€â”€ mlops/
â”œâ”€â”€ models/
â”œâ”€â”€ experiments/
â”œâ”€â”€ exports/
â”‚   â”œâ”€â”€ onnx/
â”‚   â”œâ”€â”€ tensorrt/
â”œâ”€â”€ demo/
â””â”€â”€ README.md
```

## ğŸ¥ Live Demo

ğŸ“º YouTube Demo: https://youtu.be/UQaHwTuYU6g 


## ğŸš€ Future Work

* Upgrade to YOLOv8-Medium
* Improve small-object detection
* INT8 Quantization
* Multi-sensor fusion (LiDAR + Camera)
* Real vehicle hardware integration

## ğŸ§ª Tech Stack

* Python
* YOLOv8 (Ultralytics)
* PyTorch
* OpenCV
* ONNX
* TensorRT
* MLflow
* DVC
* Optuna

## ğŸ‘¨â€ğŸ’» Team

Developed as part of Digital Egyption Pioneers Initiative AI Cohort 2025:

* Elsayed Ali Elsayed Aboulila
* Nizar Hossam Hussein
* Abd El-Rahman Ahmed
* Ahmed Ashraf Abbas
* Mohamed Ashraf Mohamed

Supervised by:
Dr. Sherif Salem

## ğŸ Conclusion

This project goes beyond model training - it delivers a **deployable, monitored, edge-ready perception module** designed for safety-critical autonomous systems.

It demonstrates full-stack ML engineering:
From data engineering â†’ model optimization â†’ deployment â†’ monitoring.
